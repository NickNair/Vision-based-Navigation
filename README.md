# Vision-based-Navigation

## Finding the tf of the camera 

1. Calibrate the camera
2. Getting the camera coordinate with respect to ARUCO marker
3. Finding the Lidar to Marker transform 
4. Adding the tfs in the launch file

## Installing and running spatio-temporal voxel layer

1. Installing the package from binaries or souce 
2. Adding the config parameters to costmap.yaml
3. Adding the plugin in local_costmap.yaml and/or global_costmap.yaml
4. Adding/Checking the map to camera_aligned_to_depth_color_frame
5. Use NavStack as usual.

| Method/Project     | Description | Link     |
| :---        |    :-------- |          :- |
| Capstone project      | Used Realsense SDK to create map and navigate using obstacle avoidance in racing car.  | https://sisaha9.github.io/camera_mapping_navigation_website/reports/dsc180b_team_1_project_report.pdf   |
| Paragraph   | Text        | And more      |
